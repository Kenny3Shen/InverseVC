{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10004548,"sourceType":"datasetVersion","datasetId":6158323}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/nachifur/RDDM.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T10:22:57.080617Z","iopub.execute_input":"2024-11-25T10:22:57.081176Z","iopub.status.idle":"2024-11-25T10:22:59.083517Z","shell.execute_reply.started":"2024-11-25T10:22:57.081129Z","shell.execute_reply":"2024-11-25T10:22:59.082085Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'RDDM'...\nremote: Enumerating objects: 292, done.\u001b[K\nremote: Counting objects: 100% (218/218), done.\u001b[K\nremote: Compressing objects: 100% (177/177), done.\u001b[K\nremote: Total 292 (delta 118), reused 105 (delta 40), pack-reused 74 (from 1)\u001b[K\nReceiving objects: 100% (292/292), 9.22 MiB | 26.61 MiB/s, done.\nResolving deltas: 100% (133/133), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os \nos.chdir(\"/kaggle/working/RDDM/experiments/2_Image_Restoration_deraing_raindrop_noise1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T10:26:15.021527Z","iopub.execute_input":"2024-11-25T10:26:15.022137Z","iopub.status.idle":"2024-11-25T10:26:15.029874Z","shell.execute_reply.started":"2024-11-25T10:26:15.022074Z","shell.execute_reply":"2024-11-25T10:26:15.028211Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install einops ema_pytorch Augmentor -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T10:28:42.349571Z","iopub.execute_input":"2024-11-25T10:28:42.351189Z","iopub.status.idle":"2024-11-25T10:28:53.248336Z","shell.execute_reply.started":"2024-11-25T10:28:42.351139Z","shell.execute_reply":"2024-11-25T10:28:53.246238Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import os\nimport sys\n\nfrom src.denoising_diffusion_pytorch import GaussianDiffusion\nfrom src.residual_denoising_diffusion_pytorch import (ResidualDiffusion,\n                                                      Trainer, Unet, UnetRes,\n                                                      set_seed)\n\n# init \nos.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in [0])\nsys.stdout.flush()\nset_seed(10)\ndebug = False\nif debug:\n    save_and_sample_every = 2\n    sampling_timesteps = 10\n    sampling_timesteps_original_ddim_ddpm = 10\n    train_num_steps = 200\nelse:\n    save_and_sample_every = 1000\n    sampling_timesteps = 5\n    sampling_timesteps_original_ddim_ddpm = 250\n    train_num_steps = 80000\n\noriginal_ddim_ddpm = False\nif original_ddim_ddpm:\n    condition = False\n    input_condition = False\n    input_condition_mask = False\nelse:\n    condition = True\n    input_condition = True \n    input_condition_mask = True\n\nif condition:\n    if input_condition:\n        folder = [\"/home/sss/python/dataset/VOC2012/train/gt\",\n                \"/home/sss/python/dataset/VOC2012/train/fs\",\n                \"/home/sss/python/dataset/VOC2012/train/wSobel\",\n                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/gt\",\n                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/Dec\",\n                \"/home/sss/python/dataset/Celebrity Face Image Dataset/test/sobel\"]\n    else:\n        folder = [\"/home/shenss/python/dataset/VOC2012/train/gt\",\n                \"/home/shenss/python/dataset/VOC2012/train/input_ht_rgb\",\n                \"/home/shenss/python/dataset/VOC2012/test/gt\",\n                \"/home/shenss/python/dataset/VOC2012/test/input_ht_rgb\"]\n    train_batch_size = 1\n    num_samples = 1\n    sum_scale = 1\n    image_size = 256\nelse:\n    folder = '/home/shenss/python/dataset/CelebA/img_align_celeba'\n    train_batch_size = 32\n    num_samples = 25\n    sum_scale = 1\n    image_size = 32\n\nif original_ddim_ddpm:\n    model = Unet(\n        dim = 64,\n        dim_mults = (1, 2, 4, 8)\n    )\n    diffusion = GaussianDiffusion(\n        model,\n        image_size=image_size,\n        timesteps=1000,           # number of steps\n        sampling_timesteps=sampling_timesteps_original_ddim_ddpm,\n        loss_type='l1',            # L1 or L2\n    )\nelse:\n    model = UnetRes(\n        dim=64,\n        dim_mults=(1, 2, 4, 8),\n        share_encoder=0, #1 0 -1，分别对应共享编码器、两个独立的 U-Net 和一个独立的 U-Net。\n        condition=condition,\n        input_condition=input_condition\n    )\n    diffusion = ResidualDiffusion(\n        model,\n        image_size=image_size,\n        timesteps=1000,           # number of steps\n        # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])\n        sampling_timesteps=sampling_timesteps,\n        objective='pred_res_noise',  # pred_res or pred_noise\n        loss_type='l1',            # L1 or L2 or huber(SmoothL1)\n        condition=condition,\n        sum_scale = sum_scale,\n        input_condition=input_condition,\n        input_condition_mask=input_condition_mask\n    )\n\ntrainer = Trainer(\n    diffusion,\n    folder,\n    train_batch_size=train_batch_size,\n    num_samples=num_samples,\n    train_lr=8e-5,\n    train_num_steps=train_num_steps,         # total training steps\n    gradient_accumulate_every=2,    # gradient accumulation steps\n    ema_decay=0.995,                # exponential moving average decay\n    amp=False,                        # turn on mixed precision\n    convert_image_to=\"RGB\",\n    condition=condition,\n    save_and_sample_every=save_and_sample_every,\n    equalizeHist=False,\n    crop_patch=False,\n    generation = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T10:28:55.072937Z","iopub.execute_input":"2024-11-25T10:28:55.073399Z","iopub.status.idle":"2024-11-25T10:28:57.046616Z","shell.execute_reply.started":"2024-11-25T10:28:55.073353Z","shell.execute_reply":"2024-11-25T10:28:57.044948Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdenoising_diffusion_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianDiffusion\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresidual_denoising_diffusion_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ResidualDiffusion,\n\u001b[1;32m      6\u001b[0m                                                       Trainer, Unet, UnetRes,\n\u001b[1;32m      7\u001b[0m                                                       set_seed)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# init \u001b[39;00m\n\u001b[1;32m     10\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m/kaggle/working/RDDM/experiments/2_Image_Restoration_deraing_raindrop_noise1/src/residual_denoising_diffusion_pytorch.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mTF\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rearrange, reduce\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meinops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rearrange\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets.get_dataset'"],"ename":"ModuleNotFoundError","evalue":"No module named 'datasets.get_dataset'","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}