{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7089718,"sourceType":"datasetVersion","datasetId":4085269},{"sourceId":7162113,"sourceType":"datasetVersion","datasetId":4136874}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":3336.031214,"end_time":"2023-11-12T15:24:52.835504","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-12T14:29:16.80429","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.vision.all import *\nimport torchvision\nset_seed(42, True)\npath=Path(\"/kaggle/input/fvc2000-vcs-rehalf/dataset_ori\")\nfiles=get_image_files(path)\n# import wandb\n# wandb.login(key='1b23517e0f9e52312f9554d602fdf4de1b98a8f4')\ndef halftone(img):\n    if isinstance(img, PILImage):\n        img1=img.convert(\"1\").convert(\"L\")\n        return img1\n    else:\n        return img\n    \ndef gray(img):\n    if isinstance(img, PILImage):\n        img1=img.convert(\"L\")\n        return img1\n    else:\n        return img","metadata":{"_cell_guid":"3619ebc2-c53b-4279-a142-3d9b8d808ab6","_uuid":"78214bea-c53b-43fa-9538-a6159bb5b305","papermill":{"duration":54.553616,"end_time":"2023-11-12T14:30:14.718493","exception":false,"start_time":"2023-11-12T14:29:20.164877","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-18T15:01:17.299264Z","iopub.execute_input":"2024-04-18T15:01:17.299571Z","iopub.status.idle":"2024-04-18T15:01:32.551658Z","shell.execute_reply.started":"2024-04-18T15:01:17.299547Z","shell.execute_reply":"2024-04-18T15:01:32.550772Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\n\ndir_path = \"/kaggle/input/fvc2000-vcs-rehalf/dataset_ori\"\ndir_names = [name for name in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, name))]\nlabel_to_num = {label: num for num, label in enumerate(dir_names)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dir_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义label_func函数\ndef label_func(filepath):\n    return filepath.parent.name\n\nclass TripletImage(fastuple):\n    def show(self, loss=None, pred=None, p=None, ctx=None, **kwargs): \n        if len(self) > 3:\n                img1,img2,img3,similarity = self\n        else:\n            img1,img2,img3 = self\n            similarity = 'Undetermined'\n        if not isinstance(img1, Tensor):\n            if img2.size != img1.size: img2 = img2.resize(img1.size)\n            if img3.size != img1.size: img3 = img3.resize(img1.size)\n            t1,t2,t3 = tensor(img1),tensor(img2), tensor(img3)\n            t1,t2,t3 = t1.permute(2,0,1),t2.permute(2,0,1),t3.permute(2,0,1)\n        else: t1,t2,t3 = img1,img2,img3\n        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n        if loss == None:\n            return show_image(torch.cat([t2,line,t1,line,t3], dim=2), title=similarity, ctx=ctx, **kwargs)\n        elif pred == None:\n            return show_image(torch.cat([t2,line,t1,line,t3], dim=2), title=f\"{loss:.2f}\", ctx=ctx, **kwargs)\n        return show_image(torch.cat([t2,line,t1,line,t3], dim=2), title=f\"{pred}/{similarity} {loss:.2f} / {p:.2f}\", ctx=ctx, **kwargs)\n\nclass TripletTransform(Transform):\n    def __init__(self, files, label_func, splits):\n        self.labels = files.map(label_func).unique()\n        self.lbl2files = {l: L(get_image_files(path/l)) for l in self.labels}\n        self.label_func = label_func\n        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n        \n    def encodes(self, f):\n        f2, f3, anchor = self.valid.get(f, self._draw(f,0))\n        img1,img2,img3 = PILImage.create(f),PILImage.create(f2),PILImage.create(f3)\n        return TripletImage(img1, img2, img3, int(label_to_num[anchor]))\n    \n    def _draw(self, f, split=0):\n        cls1 = label_func(f)\n        cls2 = random.choice(L(l for l in labels if l != cls1))\n        while len(self.lbl2files[cls2]) == 0: \n            cls2 = random.choice(L(l for l in labels if l != cls1))\n        return random.choice(self.lbl2files[cls1]),random.choice(self.lbl2files[cls2]),cls1\n    \n@typedispatch\ndef show_batch(x:TripletImage, y, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): TripletImage(x[0][i], x[1][i], x[2][i], x[3][i]).show(ctx=ctx)\n    \nsplits = RandomSplitter(seed=42)(files)\nlabels = list(set(files.map(label_func)))\ntfm = TripletTransform(files, parent_label, splits)\ntls = TfmdLists(files, tfm, splits=splits)\n\ndls = tls.dataloaders(after_item=[Resize(160), ToTensor], \n    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])\n\n#*aug_transforms()\nclass TripletModel(Module):\n    def __init__(self, encoder, head):\n        self.encoder,self.head = encoder,head\n    def forward(self, x1, x2, x3):\n        x1 = self.encoder(x1)\n        x2 = self.encoder(x2)\n        x3 = self.encoder(x3)\n        ftrs = torch.cat([x1, x2, x3], dim=1)\n#         x1 = self.head(x1)\n#         x2 = self.head(x2)\n#         x3 = self.head(x3)\n#         return x1, x2, x3\n        return self.head(ftrs)","metadata":{"_cell_guid":"7298ca9b-41b3-496d-b6f1-06c42ee2e524","_uuid":"77d7933f-29ef-469b-8a01-a81cfadadbd9","papermill":{"duration":8.769438,"end_time":"2023-11-12T14:30:23.492339","exception":false,"start_time":"2023-11-12T14:30:14.722901","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"papermill":{"duration":2.579959,"end_time":"2023-11-12T14:30:26.094066","exception":false,"start_time":"2023-11-12T14:30:23.514107","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EffNet=mobilenet_v2(weights=\"DEFAULT\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nencoder = create_body(EffNet, cut=-1)\nhead = create_head(1280*3, 10, [1024,128], ps=0.5)\nmodel = TripletModel(encoder, head)","metadata":{"papermill":{"duration":1.183193,"end_time":"2023-11-12T14:30:27.290937","exception":false,"start_time":"2023-11-12T14:30:26.107744","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def triplet_splitter(model):\n    return [params(model.encoder), params(model.head)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn = Learner(dls, model, loss_func=triplet_loss_func(margin=1.00), opt_func=Adam,\n#                 splitter=triplet_splitter, metrics=[accuracy,precison,recall,f1_score],\n#                 cbs=[PrintBestThreshold()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = Learner(\n    dls, \n    model, \n    loss_func=CrossEntropyLossFlat(), \n    splitter=triplet_splitter, \n    metrics=[accuracy, Precision(average='macro'), Recall(average='macro')],\n    cbs=[ShowGraphCallback, SaveModelCallback]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.freeze()\nlearn.fit_one_cycle(3, 1e-2)","metadata":{"_cell_guid":"06274d34-2207-4f2c-bedb-51f5978e3d09","_uuid":"a8f4db32-a868-46b3-b051-94694e75f383","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":1409.093015,"end_time":"2023-11-12T14:55:07.479852","exception":false,"start_time":"2023-11-12T14:31:38.386837","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(1e-5,1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@typedispatch\ndef show_results(x:TripletImage, y, samples, outs, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): \n        title = f'Actual: {[x[3][i].item()]} \\n Prediction: {[y[3][i].item()]}'\n        TripletImage(x[0][i], x[1][i], x[2][i], title).show(ctx=ctx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.show_results()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne = TSNE(n_components=2)\noutput = tsne.fit_transform(ftrs.cpu().detach().numpy())\nfor i in range(len(output)):\n    plt.plot(output[i, 0], output[i, 1], '.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.export('mobilenet_v2_Tri_Ori.pkl')\n#learn = load_learner('.pkl', cpu=False)","metadata":{"papermill":{"duration":0.548374,"end_time":"2023-11-12T15:24:50.216224","exception":false,"start_time":"2023-11-12T15:24:49.66785","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}